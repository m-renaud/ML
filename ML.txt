-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Machine learning code.
--   
--   Please see README.md
@package ML
@version 0.1.0.0


-- | Type aliases for activation functions and their derivative.
module ML.NN.ActivationFunction

-- | An activation function for a neuron.
type ActivationFunction = R -> R

-- | The derivative of a neuron activation function.
type ActivationFunctionDerivative = R -> R


-- | Activation functions and their derivatives for use with neural
--   networks.
module ML.NN.Activation

-- | The sigmoid function:
--   <a>https://en.wikipedia.org/wiki/Sigmoid_function</a>.
sigmoid :: ActivationFunction

-- | The derivative of the sigmoid function.
sigmoid' :: ActivationFunctionDerivative


-- | Simple neural network implementation, for learning purposes only.
module ML.NN

-- | An activation function for a neuron.
type ActivationFunction = R -> R

-- | The derivative of a neuron activation function.
type ActivationFunctionDerivative = R -> R

-- | A layer in a neural network is a bias vector and weight matrix.
--   
--   Let <i>n</i> be the number of neurons in the layer and <i>m</i> be the
--   number of inputs to the layer. Then <a>layerBiases</a> is a vector in
--   Rⁿ and <a>layerWeights</a> is an <i>nxm</i> real matrix.
data Layer
Layer :: Vector R -> Matrix R -> Layer

-- | A vector in Rⁿ representing the neuron biases.
[layerBiases] :: Layer -> Vector R

-- | An <i>nxm</i> real matrix of the neuron weights.
[layerWeights] :: Layer -> Matrix R

-- | A network is a list of layers.
data Network
Network :: [Layer] -> Network

-- | Layers in the neural network.
[networkLayers] :: Network -> [Layer]

-- | Generate a randomly initialized layer in a neural network.
randLayer :: RandomGen g => Int -> Int -> Rand g Layer

-- | Generate a random neural network given the sizes of each of the
--   layers.
--   
--   For example, <tt>[3,2,4]</tt> will generate a neural network with 3
--   input neurons, 1 hidden layer with 2 neurons and 4 output neurons.
randNetwork :: RandomGen g => [Int] -> Rand g Network

-- | Feed the output from a previous layer to the next layer.
feedForward :: ActivationFunction -> Vector R -> Layer -> Vector R

-- | Run a neural network.
runNetwork :: Network -> ActivationFunction -> Vector R -> Vector R

-- | Configuration for training a network.
data TrainingConfig
TrainingConfig :: Int -> R -> ActivationFunction -> ActivationFunctionDerivative -> CostDerivative -> TrainingConfig

-- | Number of epochs of training to perform.
[trainingEpochs] :: TrainingConfig -> Int

-- | η - Learning rate.
[trainingEta] :: TrainingConfig -> R
[trainingActivation] :: TrainingConfig -> ActivationFunction
[trainingActivationDerivative] :: TrainingConfig -> ActivationFunctionDerivative
[trainingCostDerivative] :: TrainingConfig -> CostDerivative

-- | A training sample.
data Sample
Sample :: Vector R -> Vector R -> Sample
[sampleInput] :: Sample -> Vector R
[sampleExpectedOutput] :: Sample -> Vector R

-- | A vectorized function which returns ∂Cₓ/∂a.
--   
--   The first parameter is the output activation, the second parameter is
--   the expected output.
type CostDerivative = Vector R -> Vector R -> Vector R

-- | Train the neural network using gradient descent.
gradientDescent :: TrainingConfig -> [Sample] -> Network -> Network

-- | The derivative of the mean squared error cost function.
mse' :: CostDerivative
instance GHC.Show.Show ML.NN.Gradient
instance GHC.Read.Read ML.NN.Gradient
instance GHC.Show.Show ML.NN.Sample
instance GHC.Read.Read ML.NN.Sample
instance GHC.Read.Read ML.NN.Network
instance GHC.Show.Show ML.NN.Network
instance GHC.Read.Read ML.NN.Layer
instance GHC.Show.Show ML.NN.Layer
instance GHC.Base.Monoid ML.NN.Gradient
